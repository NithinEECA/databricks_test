# salesforce_bundle

The `salesforce_bundle` was generated by using the default-python template.

## Getting started

1. Install the Databricks CLI for Windows- see `https://docs.databricks.com/en/dev-tools/cli/install.html#winget-installation-for-windows`. Don't install `databricks-cli` using `pip` - that gets you the legacy version! I succeeded using `winget`:
    ```
    $ winget search databricks
    $ winget install Databricks.DatabricksCLI
    ```

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks configure --token
    ```
    When prompted for a token, go to the Databricks web interface user settings area to create one, and copy-paste it into the terminal.

3. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

    This deploys everything that's defined for this project.
    For example, the default template would deploy a job called
    `[dev yourname] salesforce_ingestion_job` to your workspace.
    You can find that job by opening your workpace and clicking on **Workflows**.

4. Similarly, to deploy a Staging copy, type:
   ```
   $ databricks bundle deploy --target stag
   ```
   
5. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```
6. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run salesforce_ingestion_job
   ```

7. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html. Or read the "getting started" documentation for
   **Databricks Connect** for instructions on running the included Python code from a different IDE.

8. For documentation on the Databricks asset bundles format used
   for this project, and for CI/CD configuration, see
   https://docs.databricks.com/dev-tools/bundles/index.html.
